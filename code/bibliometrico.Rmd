---
title: "Humanities and social sciences on big data: a bibliometric analysis"
output: 
  html_document:
    toc: true
    toc_depth: 3
---


```{r setup, include=FALSE}

knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE,
  comment = '', fig.width = 8, fig.height = 3
  )

options(scipen = 999)

library(tidyverse)
library(igraph)
library(ggraph)
library(tidygraph)

metadata <- readr::read_csv(file = "../data/metadata.csv")
ocr <- readr::read_csv(file = "../data/ocr.csv")
autores <- readr::read_csv(file = "../data/autores.csv")
references <- readRDS(file = "../data/referencias/referencias.rds")

```


# Abstract


***Purpose**: In recent years, the rapid growth of big data has presented immense potential for business applications as well as raised great interest from academia. In response to this emerging phenomenon, the purpose of this paper is to provide a comprehensive literature review of big data.*
***Design/methodology/approach**: A bibliometric method was used to analyze the articles obtained from the Scopus database published between 2013 and 2018. A sample size of 4,070 articles was evaluated using SciVal metrics.* 
***Findings**: The analysis revealed an array of interesting findings as follows: 
- the number of publications related to big data increased steadily over the past six years, though the rate of increase has slowed since 2014; 
- the scope of big data research is quite broad in regards to both research domains and countries; 
- despite a large volume of publications, the overall performance of big data research is not well presented as measured by the field-weighted citation impact metric; - collaboration between different institutions, particularly in the form of international collaboration and academic–corporate collaboration, has played an important role in improving the performance of big data research.
- over 50% of publications do not receive any citations, and the average number of citations per publication is 3.17. 
- It is also observed that single authorship of research publications has declined over the time. 
- The analysis reveals the pioneering role played by the USA in advancing the research in big data, which has lately been taken over by China, and the large-scale usage of big data analytics in various domains of science.*
***Originality/value**: To the best of the authors’ knowledge, this is the first study to provide a holistic view of the big data research. The insights obtained from the analysis are instrumental for both academics and practitioners.*

**Keywords**: Big data, social sciences, humanities, bibliometric analysis, citation analysis


# Introduction


This work explores, through a bibliometric analysis, the scientific literature about "Big data" in social sciences, psychology and humanities. Working on a XXXX papers dataset retrieved from Scopus, we aim to identify trends about authorship and collaboration, topics and study areas, and the most influential works. Such objective is a particular step within a broader project aiming to compare how big data is thematized and framed in different social systems, such as mass media, science, politics, commerce, economics, among others (Becerra, 2018). 

The term "big data" originated in late 1990s in the IT sector, referring to the (technical) challenges of handling a vast amount of information (Diebold, XXXX). In a famous consultancy piece, Douglas Laney (2001) synthesized these challenges by referencing 3 v’s -volume, velocity, and variety-, a formula that expanded to include other v-words such as, visualization or value, and that usually takes the place of a definition. Ironizing this, "Vexatious vagueness" is the implicit last v-word, says Halavais (2015).

From here, big data has expanded to different areas of social life, such as politics, mass media, business, among others. Critical case studies, from a social science perspective, are still required to understand the social meaning of big data in such spaces. 

Drawing mostly on mass media discourse, in another work (Becerra, 2021) we've proposed that communications regarding big data usually include 2 highly debatable elements: a premise regarding the availability of huge volumes of data that can be exploited; and a promise that new knowledge and understandings about all aspects of human life will be reached through data analysis. These elements are part of a widespread belief, rhetoric and mythology that relate big data with other socio-technical developments, such as artificial intelligence and algorithms, and offer the promise of an objective, effective and optimal, value-free, and conflict-free social future (boyd & Crawford, 2021; van Dijck, 2014; Sadin, 2018; among others).

Scientific interest on big data has also been on the rise in the last decade. According to several studies (e.g., Belmonte, et. al., 2020; Liu et. al., 2019), and drawing on different sources, the scientific big data literature has grown yearly in a X2 rate for the 2010-2014 range; and, although this trend has slowed down, up until 2020 the number of papers per year never decreased. Others have shown that the estimated contribution from the social sciences and humanities is near the 7-10% of this corpus (Kalantari et. al., 2017; Liu et. al., 2019). 

Facing big data, social sciences and humanities found a big challenge: to criticize and discuss the premise and the promise of its rhetoric and mythology, to disect the social beliefs and ideologies around it, to illuminate the extent of social and ethical issues that it brings, and to re-shape it from within to advance our understanding of ourselves. 

To dwell on a few of these: 

* philosophy and other humanities have been discussing the harms of research on big social data -e.g., data collection through Facebook apps and active campaigns-, pinpointing issues on privacy and social reactivity in a time when the research/experimentation seems to be fading and regulatory definitions demand revisions (Metcalf & Crafword, 2016; Mai, 2016; Leonelli, 2016; Weinhardt, 2020; Zuboff, 2015); 
* social sciences and epistemology have warned that big social data, and any other sources generated in the datafication process, are embedded with limitations and conditioning from the data gathering/creation settings, and that also the data curation process required for algorithmical analysis is a heavily decision task that challenge the neutrality and objectivity of some data science claims (Mutzel, 2015; Gitelman, 2013; Qiu et. al., 2018)
* also social sciences, psychology and humanities have been discussing different integrations big data in social research, in a way that could allow to guide data-driven analysis through the rich theoretical awareness of these traditions (Frade, 2016; Halford & Savage, 2017; Burrows & Savage, 2014; boyd & Crawford, 2012). As Halavais (2015) synthezises with regards to sociology:

> "Big data does provide a challenge to the social sciences, but not a particularly new one. It is, in fact, the core challenge of sociology: connecting the micro-connections between individuals to the vast social structures that shape us (and are shaped by us) as a society. Mills famously suggested that this ability to both connect and disconnect the personal with the social was at the core of what he called the ‘sociological imagination’."

In this paper we focus on papers from social sciences, psychology and humanities and arts. We do so in a bibliometric approach that aims at assessing and analyzing in a quantitative manner trends in the publications. Specifically, we are interested in 3 key issues for which bibliometric analysis has proven to be an useful and a valid methodology: (1) Authorship: access to big data is unequal because of costs and skills. This is true for the users and citizens but also within the academic world (McCarthy, 2016). Analyzing authorship is a way to shed some light on these issues. Also, although using co-authorship as proxy for real academic collaboration has been discussed (Ponomariov & Boardman, 2016), it is indeed and interesting metric to explore trends in integration and crossings between nations and types of institutions (e.g., academia and private sector), which are argueably challenges required for big data research; (2) Contents: big data is a trans-disciplinary area of research with no clear taxonomy nor classifications. Analyzing content in a statistical manner can help us gain insights about the different ways in which it is framed and thematized in the different branches of knowledge; (3) Citations: although citation should not be taken as a valid tool to assess the quality of a publication, it is indeed a valuable metric to assess visibility and influence (Eibrahim, 2014). Hence, bibliometrics that draw on citation analysis are useful to identify possible trends and other eigen-values on topics and approaches. Several papers used bibliometric and citations analysis to map the big data scientific production, including these issues (we'll review these in the next section), but to the best of our knowledge, no one has focus on the social sciences and humanities. 

Our research questions are:

* **RQ1** Cuál es la dinámica  de autoría y colaboración? 
  * **RQ1.1** What is the average number of authors per publications per year? 
  * **RQ1.2** Cuales son los paises que más publicaron? Cómo es la colaboración entre paises?
  * **RQ1.3** Cuales son las instituciones con mas articulos en academia / fuera? Como es la colaboracion entre instituciones?
* **RQ2** What are the key topics/areas that are addressed in publications? 
  * **RQ2.1** frecuencia de keywords
  * **RQ2.2** relaciones entre keywords (red y mapa semantico)
  * **RQ2.3** cuales son los temas? (topic modelling)
  * **XXXXX como se tematiza el big data? (para otro laburo!)**
* **RQ3** Citaciones
  * **RQ3.1** top venues <------------- no esta hecho
  * **RQ3.2** What are the top cited publications for each year in the selected time frame? Articulos más influyentes (+citas)
  * **RQ3.3** cuantas citas por año?
  * **XXXXX  a que clasicos se cita? (para otro laburo!)**


# Related works


**(TRATAMIENTO BIBLIOMETRICO DEL BIG DATA)**

Los mas generales. 

xxxxxxxxxxxxxxxxxxxxxx LOS UQE YA ESTAN:

Ahmad, I., Ahmed, G., Shah, S. A. A., & Ahmed, E. (2020). A decade of big data literature: analysis of trends in light of bibliometrics. Journal of Supercomputing, 76(5), 3555–3571. 

Using Scopus as the data source, we perform a thorough analysis of scholarly works published in the field ofbig data from 2008 to 2017.

Our choice for data collection is Scopus because of service availability, ease of use and authenticity of the data [26]. 
Therefore, we chose 2008 as starting year for our data extraction. Thus, the time frame spans a decade of research in the field. Our search criteria have resulted in total of 34,655 documents. Using the graphical user interface provided by Scopus, we exclude some document types namely conference review, editorial notes, and letters. The main motivation behind the omission of these document type resides in the fact that they mostly provide information about the outlet such as scope of the conference/special issue, the number of submissions, and the acceptance rate, and normally have very low citation counts. The omission of these documents reduced the documents number to 33,623. As stated earlier that big data is a transdisciplinary field, we did not limit to literature from computer science only and allowed results fromdiverse fields such as business, medical science, and social sciences.


Liu, X., Sun, R., Wang, S., & Wu, Y. J. (2019). The research landscape of big data: a bibliometric analysis. Library Hi Tech, 38(2), 367–384. https://doi.org/10.1108/LHT-01-2019-0024

A bibliometric method was used to analyze the articles obtained from the Scopus database published between 2013 and 2018. A sample size of 4,070 articles was evaluated using SciVal metrics.


Kalantari, A., Kamsin, A., Kamaruddin, H. S., Ale Ebrahim, N., Gani, A., Ebrahimi, A., & Shamshirband, S. (2017). A bibliometric approach to tracking big data research trends. Journal of Big Data, 4(1), 1–18. https://doi.org/10.1186/s40537-017-0088-1

For example, Kalantari et al. (2017) adopted the bibliometric approach to analyze 6,572 papers relevant to big data research, which were published in the Web of Science core collection database between 1980 and 2015. 

In this study, bibliometric tools have been selected to determine the major and essen-
tial research trends in the field of big data research, and the most relevant research areas upon which big data has a significant impact. The Thomson Reuters’ Web of Sci- ence (WoS) database is used to extract the bibliometric information for “big data”. The WoS is a structured database that indexes selected top publications that, covering the majority of significant scientific results [13]. A total of 6572 papers were collected from WoS and the aim of this research is to provide a comprehensive analysis and evaluate the latest research trends followed by the Document Type and Language, Publication output, Contribution of Countries, Top WoS Categories and Journals, Top Authors, Top Research Areas and Analysis of Author Keywords and Keyword Plus related to the field of big data and its most relevant research areas


Liu, X., Sun, R., Wang, S., & Wu, Y. J. (2019). The research landscape of big data: a bibliometric analysis. Library Hi Tech, 38(2), 367–384. https://doi.org/10.1108/LHT-01-2019-0024

A bibliometric method was used to analyze the articles obtained from the Scopus database published between 2013 and 2018. A sample size of 4,070 articles was evaluated using SciVal metrics.


Liang, T. P., & Liu, Y. H. (2018). Research Landscape of Business Intelligence and Big Data analytics: A bibliometrics study. Expert Systems with Applications, 111(128), 2–10. https://doi.org/10.1016/j.eswa.2018.05.018

Liang and Liu (2018) used the bibliometric method to explore the research and development trends of research pertaining to big data and business intelligence based on three databases: Social Science Citation Index, Science Citation Index Expanded and Arts & Humanities Citation Index. 

n this article, we review academic literature associated with “Big Data” and “Business Intelligence” to explore the devel- opment and research trends. We use bibliometric methods to analyze publications from 1990 to 2017 in journals indexed in Science Citation Index Expanded (SCIE), Social Science Citation Index (SSCI) and Arts & Humanities Citation Index (AHCI). We map the time trend, disciplinary distribution, high-frequency keywords to show emerging topics

Our search using “Big Data” and “Business Intelligence as key
words resulted in the database that includes 10,637 publications associated with “Big Data” and 1168 publications associated with “Business Intelligence.” Among these documents, 141 publications contain both “Big Data” and “Business Intelligence.”

How research topics change and evolve in these academic out- puts?
• Which discipline drives the related research? • Who are major contributors toward these outputs? Which pa- per is the most influential?
• What are the most-cited references among these outputs?   


Zhang, Y., Huang, Y., Porter, A. L., Zhang, G., & Lu, J. (2019). Discovering and forecasting interactions in big data research: A learning-enhanced bibliometric study. Technological Forecasting and Social Change, 146(April), 795–807. https://doi.org/10.1016/j.techfore.2018.06.007

We draw on 5840 articles derived from the Web of Science (WoS) to
conduct this study. Specifically, the R&D profile is to review the land- scape of big data research by: 1) profiling the statistical dynamics and geographic distribution of related scientific articles; and 2) identifying the core constituents, i.e., the leading journals, organizations, and countries, and their competitive and collaborative relationships in this area. The scientific evolutionary pathways (SEP) create a solution to detect and visualize the technological changes in big data research from 2000 to 2015, in which a learning process is used to track the inter- active relationships between topics in sequential time slices, revealing technological evolution and death by identifying predecessors and descendants of big data topics. At the end, we combine expert knowl- edge and our analytic results to foresee future directions of big data research in the near future and provide recommendations.




Hay otros que son específicos de un área o tema


Mishra, D., Gunasekaran, A., Papadopoulos, T., & Childe, S. J. (2018). Big Data and supply chain management: a review and bibliometric analysis. Annals of Operations Research, 270(1–2), 313–336. https://doi.org/10.1007/s10479-016-2236-y

For example, by applying the bibliometric method and network technique, Mishra et al. (2018) produced a literature review concerning big data and supply chain management on the basis of an assessment of 286 articles published in the previous decade. 


Rialti, R., Marzi, G., Ciappei, C., & Busso, D. (2019). Big data and dynamic capabilities: a bibliometric analysis and systematic literature review. Management Decision, 57(8), 2052–2068. https://doi.org/10.1108/MD-07-2018-0821

Recently, several manuscripts about the effects of big data on organizations used dynamic capabilities as their main theoretical approach. However, these manuscripts still lack systematization. Consequently, the purpose of this paper is to systematize the literature on big data and dynamic capabilities. Design/methodology/approach – A bibliometric analysis was performed on 170 manuscripts extracted from the Clarivate Analytics Web of Science Core Collection database. The bibliometric analysis was integrated with a literature review
The first one deals with the implementation of BDA systems for supply chain management and the second is about the effect of big data and BDA on supply chain management performance.



## 1/ autoria

Ahmad, I., Ahmed, G., Shah, S. A. A., & Ahmed, E. (2020). A decade of big data literature: analysis of trends in light of bibliometrics. Journal of Supercomputing, 76(5), 3555–3571. https://doi.org/10.1007/s11227-018-2714-x

Geographically, China has the most number of publications, followed by USA. However, in the initial years, China has no significant contribution. This confirms the leadership role played by USA in the field. 

Nobre and Tavares [48] analyzed the literature related to the application of big
data/IoT in the context of circular economy indexed in Scopus for the time frame 2006–2015. The study found that China and USA are the most active countries

Table 6 presents the yearly contribution by the top 10 countries. Geographically, China has contributed the most number of publications (8901), followed by the USA (8568), and India (2342). It is interesting to note that during the years 2008–2011 China has produced only 4 papers (zero publication prior to 2011), whereas USA has produced 36 publications. During the same period, the other top-10 countries (excluding China) contributed 23 publications, i.e., the cumulative sum of 9 countries (27) is less than that of USA (36). These numbers establish the fact that the USA played a pioneering role in big data research and is later joined by other countries. It is also observed that during the period 2008–2011 Japan (1 paper in each year) and South Korea (1 paper in 2010) are the only Asian countries to publish in the domain. It can also be seen that China leapfrogged USA in the last two years only.


For the complete time frame (2008–2017), the average number of authors per publica- tion is 3.45 with a standard deviation of 2.34. In total, 13.67% of articles are published with a single authorship, and 41% of articles have more than the average number of authors, i.e., 41% of publications have at least 4 authors. The surprising aspect of the findings is the share of publications with more than 10 authors. We found that 1% of the papers have more than 10 authors. Figure 4 summarizes the number of authors per publication distribution. of publications have single authorship. During the later years, the single authorship trend declines. In 2016, only 11.6% of papers have single authorship, the minimum for the selected time frame. Figure 5 depicts the authorship trends for the time frame. It should be noted that as the number of publications are significantly lower for initial years, the data for years 2008–2012 are combined for reporting purposes.

FIG 5 SE PUEDE REPLICAR


Inamdar, Z., Raut, R., Narwane, V. S., Gardas, B., Narkhede, B., & Sagnak, M. (2020). A systematic literature review with bibliometric analysis of big data analytics adoption from period 2014 to 2018. Journal of Enterprise Information Management. https://doi.org/10.1108/JEIM-09-2019-0267

(ctx = literatura sobre Application areas Manufacturing / Supply chain / Manufacturing supply chain Service / Manufacturing service sector Healthcare / Others)

From the CiteSpace analysis, the People’s Republic of China emerged as the topmost contender with the highest citation count of 203 and the centrality of 0.03. The United States of America with 144 citation counts and centrality of 0.12 followed second while the third- highest citation count emerged from England (citation count of 74 and centrality of 0.32). (Annexure, Table AI illustrates the results of the most cited countries as per CiteSpace).

Liu, X., Sun, R., Wang, S., & Wu, Y. J. (2019). The research landscape of big data: a bibliometric analysis. Library Hi Tech, 38(2), 367–384. https://doi.org/10.1108/LHT-01-2019-0024

According to the author’ affiliation, the analysis revealed that a total of 99 countries contributed to the generation of the articles sampled. Figure 5 lists the top 10 countries building upon scholarly outputs. Of the top 10 countries, China and the USA are the top 2 that show their publications on big data are beyond 1,000

Collaborative authorship Through further examination, the sample found that 83.9 percent of articles are written using co-authorship. According to SciVal metrics, two categories of collaboration are suggested: co-authorship by geographic location and academic–corporate collaboration (ACC), as shown below.
Co-authorship by geographic location. In the category of co-authorship by geographic location, there are four types of collaboration, i.e. International Collaboration, National Collaboration, Institutional Collaboration and Single Authorship. Single Authorship means there are no co-authors in one study. Multiple authors from the same institution represent Institutional Collaboration. Multiple institutions located in the same country denote National Collaboration. If the fellowship includes multiple institutions from multiple countries, it is classified as International Collaboration. In terms of this classification, the finding revealed that Institutional Collaboration achieved 39.3 percent (1,600) of the collaborative papers, followed by International Collaboration with 26.3 percent (1,070). National Collaboration and Single Authorship accounted for 18.3 percent (743) and 16.1 percent (657), respectively. 4.2.2 Co-authorship by ACC. Among the collaborative papers, 112 (2.8 percent) are
produced through the manner of ACC. Due to the small amount of publications on this topic, this finding is likely to indicate that, in the field of big data research, joint work contributed by both academia and industry is not popular. Table I outlines the top 10 institutions and countries/regions in the form of ACC publication. As listed in Table I, six of the institutions are affiliated with the USA, whereas the other four are relevant to China and Switzerland. In terms of countries, the USA ranks at the top with over half ACC publications (60/54 percent). China (24/21 percent), the UK (14/13 percent) and Canada (12/11 percent) have published more than ten ACC articles. The countries do not have a big representation in ACC articles



Kalantari, A., Kamsin, A., Kamaruddin, H. S., Ale Ebrahim, N., Gani, A., Ebrahimi, A., & Shamshirband, S. (2017). A bibliometric approach to tracking big data research trends. Journal of Big Data, 4(1), 1–18. https://doi.org/10.1186/s40537-017-0088-1

It has been reported that, “Each author of an article has made an independent contri- bution to the manuscript and therefore the institution and country the author affiliated could be considered the important contributors for the evaluation of research” [78, 79]. Consequently, the number of publication counts for each country were used to evaluate the research contribution of any region/country in the related field. Figure 4 shows the geographical distribution of the published papers in the world rele- vant to the field of big data. As shown in Fig. 4, the USA (1852) was the most productive country with the largest number of publications regardless of the participation of inter- national collaborators, followed by China (1059), Germany (303), England (285), Spain (282), Canada (255), India (253), France (226), Italy (198) and Australia (193). The geographical world map shows that there has been a gradual increase in the num-
ber of publications in North and South America, and that it has a higher impact in the world. We found that among the 196 countries in the world, 96 countries such as South Africa and a few countries in the Middle East have no publications. The present results show that big data is a growing area of research in most countries


Zhang, Y., Huang, Y., Porter, A. L., Zhang, G., & Lu, J. (2019). Discovering and forecasting interactions in big data research: A learning-enhanced bibliometric study. Technological Forecasting and Social Change, 146(April), 795–807. https://doi.org/10.1016/j.techfore.2018.06.007

(con simulaciones y forecasting)

Big data-related research has been conducted for several decades, but the boom started in 2010.
• The hotspots in big data analytics are concentrated on machine learning and cloud computing. MapReduce and Hadoop are still the two leading tools. The applications of big data analytics have been well involved with bioinformatics and internet of things.
• Beside Nature and Science, journals in the areas of computer science, business and management, and bioinformatics are playing active roles in publishing big data-related academic articles, while positive impacts of mathematic and physical journals can also be traced.
• With extensive collaborative networks with both Europe and Asia, the US leads big data research globally, and Europe illustrates strong competitiveness. China is demonstrating great potential in both re- search quantity and collaborations. However, collaboration within Asian academic institutions (especially Japan and South Korean) are somewhat limited.
• The role of world‑leading universities and academic institutions in pushing big data research forward is significant, and examples of the alliance of giants occur here and there


## 2/ contenidos

Liao et al. [43] performed bibliometric analysis of big data literature published in the field of medical big data. The authors used Science Citation Index Expanded and the Social Science Citation Index databases as data sources to extract 988 references. Therewere no restrictions on the time span. The novelty of the work is the application of multi-regression analysis considering the number of authors, number of pages, and number of references. It was observed that the medical big data literature has seen a rise after 2010. By analysis of the keywords, it was identified that the medical care is shifting its focus toward patient-centered model than disease-centered approach.

Ahmad, I., Ahmed, G., Shah, S. A. A., & Ahmed, E. (2020). A decade of big data literature: analysis of trends in light of bibliometrics. Journal of Supercomputing, 76(5), 3555–3571. https:/

Unlike other scientific fields that have clear taxonomy and classification of the sub- ject area [8], there is no classification scheme for big data. We use the frequency of keywords as metric to identify sub-areas and topics that gained the attention of researchers over the course of time. Our analysis found that the phrase “Big Data” is the most widely used keyword in our collection of records, which is unsurprising. The other keywords in order of occurrences are Data Mining (4995), Data Handling (4242) Digital Storage (3185), Cloud Computing (2921), Information Management (2795), Artificial Intelligence (2769), Distributed Computer Systems (2515), Learn- ing Systems (2261), and Algorithms (2027). In order to make the comparisons more realistic, we removed the keyword “Big Data” and designed a word cloud using the statistical software R (see Fig. 1).


Kalantari, A., Kamsin, A., Kamaruddin, H. S., Ale Ebrahim, N., Gani, A., Ebrahimi, A., & Shamshirband, S. (2017). A bibliometric approach to tracking big data research trends. Journal of Big Data, 4(1), 1–18. https://doi.org/10.1186/s40537-017-0088-1

This section provides the research areas between all and highly cited papers, which were sorted by the number of records based on the total publications. Overall, there were 54 research areas for the all papers group and 11 research areas for the highly cited group. As shown in (Additional file 1), the top two research areas for both groups were Com- puter Science and Engineering, with the highest number of records and the respective number of publications in other research areas showing that there are slightly different research areas compared to each group. The result shows that the most relevant research areas were in Computer Science with the highest number of publications. However, there were other important research areas with a lower number of records. For instance, in the research areas for the all papers group, this was followed by “Telecommunica- tions” (527), “Operations Research Management Science” (194), “Medical Informatics” (184) and for the highly cited group it was followed by “Mathematics” (4), “Biochemistry Molecular Biology” (3), and “Biotechnology Applied Microbiology” (3).

Author keyword is one of the essential types of information about the research trends from the view of researchers and has been proven to be important for monitoring the development of science [82–84]. In this study, 10,002 author keywords were used for the analysis from 1980 to 19
March 2015. Table 8 depicts the top 20 frequency for the author keywords used in all papers. The author keywords were compared by the total number of records for three different periods. The distribution of each keyword would assist the researchers to iden- tify the importance of each author keyword used in different years or decades. Accord- ingly, the result shows that among the top 20 frequency for author keywords, only a few keywords were used between 1980 and 1999. These included “machine learning”, “data warehouse”, “data mining”, “classification”, “neural networks” and “clustering”. However, over the past 15 years the number of keywords increased.


Liang, T. P., & Liu, Y. H. (2018). Research Landscape of Business Intelligence and Big Data analytics: A bibliometrics study. Expert Systems with Applications, 111(128), 2–10. https://doi.org/10.1016/j.eswa.2018.05.018

Table 2 summarizes the high frequency keywords of the “Big
Data” and “Business Intelligence” publications. The keywords are listed in descending order of frequency. Among the 10,637 “Big Data” publications, the top 5 associated keywords are “model”, “al- gorithm”, “system”, “MapReduce” and “cloud computing”. Among the 1168 “Business Intelligence” publications, the top five keywords are “management”, “data warehouse”, “Big Data”, “data mining” and “systems.” Although a few keywords such as “data mining”, “social media” and “management” are overlapped, we see signifi- cant discrepancy between these two groups of research. BD-related keywords are more emphasize on algorithm and computing, while BI-related keywords are more focused on management and deci- sion support systems. The evidence is consistent with our argu- ment that BD is more technical whereas BI is more application- oriented.

Fig. 3 shows the visualized cloud of keywords in the 10,637
BD publications. Important keywords are highlighted with larger fonts, while the color of a keyword is determined by the clus- ter to which the keyword belongs. Lines among key words indi- cate the strongest co-citation links between keywords. “Big Data” is the center of the cloud since it is the search key. Consistent with Table 2 , “model”, “algorithm”, “system”,” “cloud computing”, “management”, “networks” and “information” are all highlighted key words. In the tag cloud, five main clusters labeled by dif- ferent colors belong to 5 different main areas. The red cluster is formed by healthcare area publications, and the green cluster be- longs to computer science area. “Business Intelligence” is on the top front belonging to the yellow cluster. The yellow cluster mainly belongs to the management field. “Business Intelligence” is directly linked with “management”, “data analytics” and “predictive analyt- ics”, while “knowledge management” is bigger in the same cluster.


Zhang, Y., Huang, Y., Porter, A. L., Zhang, G., & Lu, J. (2019). Discovering and forecasting interactions in big data research: A learning-enhanced bibliometric study. Technological Forecasting and Social Change, 146(April), 795–807. https://doi.org/10.1016/j.techfore.2018.06.007

(con simulaciones y forecasting)

• Unstructured data is highlighted in big data research, and exploring insights from audio and video streaming is one of the basic requirements raised in the Big Data Initiative. At the same time, the definitions of metadata and unstructured data have overlapped and become broader in scope. They now cover rich information from almost all sectors of the real world, and, therefore, analyzing me- tadata has already become a hotspot in big data research.
• The majority of big data analytic techniques appeared long before the big data boom. Techniques and algorithms such as statistical analysis, classification, machine learning, and support vector ma- chine are within this range. However, upgrading, optimizing, and recombining these techniques for big data have become emergent tasks. Prediction models are one such example, where big data techniques are now focused on solving the problems of both gov- ernment and industry simultaneously.
• Distributed systems are not new and, as shown in Table 6, appeared as a topic in 2003 and its related research definitely started long before then. However, its importance was dramatically raised be- cause of Hadoop, the programming framework used in distributed computing environments. A similar situation might also occur with parallel computing and MapReduce.
• Supporting medical diagnoses by analyzing large-scale medical re- cords is currently highlighted. The project Big Data to Knowledge (Margolis et al., 2014), a response to the Big Data Initiative from the National Institutes of Health (NIH) in 2013, pushed this emergent task forward. As indicated in Fig. 4, bioinformatics can be con- sidered as one of the most successful applications of big data ana- lytics.



## 3/ citas

Ahmad, I., Ahmed, G., Shah, S. A. A., & Ahmed, E. (2020). A decade of big data literature: analysis of trends in light of bibliometrics. Journal of Supercomputing, 76(5), 3555–3571. https://doi.org/10.1007/s11227-018-2714-x

The study systematically analyzed the citations of publications in Big Data to answer a variety of research questions. Although our data start from 2008, we observe, rather surprisingly, that none ofthe top-10 publications are published between2008and 2011.

As expected, the highest cited publications include survey papers in the field. We also found that over 50% of publications are not cited, and 80% of citations are received by 12.74% of publications.

We also observed that average number of citation per publication to be 3.17, whereas the average number of authors per publication is 3.45. The current study is based on citation count as metric and treats every citation equally. In other words, it does not differentiate between a citation included for the sake of completeness of work, and the one which forms the foundation of a research work. It will be interesting to perform content-based citation analysis of the field and identify important works based on the context as well. Another research direction will be to analyze the citation counts differences between various sources, and compare the ranking.

Culnan [18] analyzed and compared the citation patterns of aca- demics and practitioners who published in the proceedings of a national computer science conference. The study identified that both the groups under consideration (academicians and practitioners) cited the same core journals, as well as documents belonging to the same age group.

Table 2 presents the top 10 publications based on the absolute number of citations received. Rather unsurprisingly, most ofthe top 10 research publications includeworks that are survey in nature. One of the interesting exceptions is the work on Rank # 5 which reports findings of an experimental study of Facebook [1]. The authors investigated if emotional contagion occurs on Facebook by analyzing contents in the newsfeed of users. Reducing positive contents lead to the reduction of positive posts and an increase in negative posts. Same trends were observed when negative expressions were reduced in the news feed. The authors concluded that emotional states are transferable to other via emotional contagion

Table 2 Top 10 publications by citation count Rank
Business intelligence and analytics: From big data to big impact
Critical questions for big data: Provocations for a cultural, technological, and scholarly phenomenon
Data mining with big data
Internet of Things: A survey on enabling technologies, protocols, and applications
Experimental evidence of massive-scale emotional contagion through social networks
The parable of google flu: Traps in big data analysis Big data: A survey
Internet of things in industries: A survey
Data-intensive applications, challenges, techniques and technologies: A survey on Big Data
Private traits and attributes are predictable from digital records of human behavio

We identify the top 10 venues for publications in terms of number of citations. In addition, we also record the number of publication made in each venue. Lecture Notes in Computer Science (LNCS)2 received the most number of citations (3064), which published the most number of articles as well (2538). This resulted in 1.20 citations per publication. LNCS is followed by Proceedings of the VLDB Endowment which received 2369 citations for 99 publications.

The complete set of publications received 1,06,598 citations, which equates to 3.17 citations per publication. A vast majority (55%) has not received any citation. The number is significantly higher than reported in other studies [24,26]. Garousi and Fer- nandes [24] reported that 43% of research publications have zero citation count when analyzing the literature of software engineering. 15% of publications have received only a single citation which is in the same range as reported in [26].

of the data shows that 94% of publications have received no more than 10 citations, and 0.8% have received over 50 citations. Figure 2 presents an overview of the citation distribution. An important question regarding the citation landscape of a set of publication is
related to the applicability ofpower law [11]. It is often stated that citations ofscientific publications follow heavy tail distribution (see [11] and references therein). In citation networks, it means that 80% of the citations are received by 20% of publications. Although the full investigation regarding the fitness of our data to power law is beyond the scope of this work, we will like to highlight that in our collected data, 80% citations are received by the top 12.74% publications (see Fig. 3), i.e., the vast majority of citations are received by relatively fewer number of publications.



Kalantari, A., Kamsin, A., Kamaruddin, H. S., Ale Ebrahim, N., Gani, A., Ebrahimi, A., & Shamshirband, S. (2017). A bibliometric approach to tracking big data research trends. Journal of Big Data, 4(1), 1–18. https://doi.org/10.1186/s40537-017-0088-1

In summary, highly cited papers are the ones that ranked within the top 1% over the past 10 years [42, 43]. Besides the highly cited papers, which were reported by ESI, the citations per year
were calculated as a division of the total citations by life year of the article. The citations per year are more accurate and more scientific than the total citations to identify the top cited papers [44, 45]. Citation statistics produced for a period of less than 3 years may not be sufficiently stable [46, 47]. Therefore, we only select the papers published up to 19 March 2015 for citation analysis. The rest of the analyses were based on the whole data- set.


Liang, T. P., & Liu, Y. H. (2018). Research Landscape of Business Intelligence and Big Data analytics: A bibliometrics study. Expert Systems with Applications, 111(128), 2–10. https://doi.org/10.1016/j.eswa.2018.05.018

Another issue we may look into is the disciplines involved in
BD and BI. We use special issues published by research journals as our evidence. Table 4 summarizes the academic fields of eight special issues on BD and BI. Three journals fall into the Computer Science field, and the others are related to Information Science and Management. This implies that computer science has been the core discipline that drives the research on BD and BI, while information science and management are also important disciplines. Table 5 presents the top 10 journals that published the highest
number of BD and BI papers in descending order. We can find that these two groups of journals have overlaps, but their top lists are quite different. Com pared to BI papers mainly published in com- puter science journals, information system and management jour- nals, BD papers were published in more diversified journals that

able 5 Major journals which published most Big Data and Business Intelligence research.
Big Data Journal
IEEE access
Counts 124
Associated fields
Computer Science, Information systems, Electrical & electronic engineering
Business Intelligence Journal
Expert Systems with Applications
Plos One 102 Multidisciplinary social sciences Decision Support Systems
Counts 38
35
Future generation computer systems
Big Data
Concurrency and Computation- Practice & Experience
Cluster Computing: the Journal of Networks, Software Tools and Applications Neurocomputing
Agro FOOD Industry Hi Tech
Journal of Supercomputing
Information Sciences
98 85 84 77
75 69
64 55 Computer science -theory & methods
Computer science- interdisciplinary applications
Computer science-software engineering, theory & methods
Computer

Table 6 Most cited publications.
Publication Chen et al. (2012)
Wang, Deb, Gandomi, and Alavi (2015) Tien, J. M. (2013)
Chang, Y. W., Hsu, P. Y., & Wu, Z. Y. (2015) Freire et al. (2016) He et al. (2015)
Fuchs, Höpken, and Lexhagen (2014) Kwon and Sim (2013)
Marine-Roig and Clavé (2015) Arnott and Pervan (2014)

---------------

# Methodology

## Procedure and Data Analysis

The research process was carried out in different actions. First the database was selected. In this
case, WoS was chosen as a database that contains a large number of indexed impact studies. Next, the keywords to be analyzed were determined. In this study the terms “Machine Learning” and “Big Data” were chosen, after consultation in various specialized thesauri. Next, the search equation was constructed. The result was “Machine Learning” [TOPIC] AND “Big Data” [TOPIC] with the intention of refining the process of reporting scientific documents that had such terms in title, abstract, and keywords of indexed publications. These first actions obtained a scientific production of 4328 documents. The first studies dated
back to the year 2010. Therefore, the literature of the last 10 years (2010-2019) was taken, suppressing studies published in 2020 (n = 74) for not having finished the year and duplicates or indexed incorrectly (n = 14). Therefore, the unit of analysis focused on 4240 documents. This figure was the result of the application of various production indicators with their respective inclusion criteria such as year of publication (all production except 2020), language (x ≥ 10), publication area (x ≥ 700), type of documents (x ≥ 100), organizations (x ≥ 50), authors (x ≥ 10), sources of origin (x ≥ 30), countries (x ≥ 200), citation (the four most cited documents; x ≥ 250). 
To analyze the reported literature, various software was used. Two are tools fromWoS, Analyze
Results and Creation Citation Report. These were used to extract the data related to the year, authorship, country, type of document, institution, language, medium and most cited documents. The other program was SciMAT, used to longitudinally analyze the structural and dynamic development of scientific production. For an effective analysis, the instructions of experts in this latest software were followed [34]. SciMAT allowed the following thematic co-word analysis to be carried out through the following processes
A key consideration in any citations-based study is the selection of data source. A number of online databases are available that provide access to the citation data. These sources include ISI Web of Knowledge, Scopus, Google Scholar and dblp. Out of these, ISI Web of Knowledge and Scopus are the two main sources used by the majority of researchers for citation data analysis [17,24,25,33,34]. Other citation databases are also used such as dblp by Hoonlor et al. [35]. Our choice for data collection is Scopus because of service availability, ease of use and authenticity of the data [26].
After selection of the source, the next step is the extraction of the required data from
the data source. Scopus provides a flexible and customized way for data extraction from its database using various criteria such as search by author name, source name, affiliation, and keywords search. We used title and keywords as our main search criterion, i.e., we queried the database to return all documents where the word “Big Data” is located either in the title of the document or in the associated keywords. We also restricted the results to English language articles and articles published between 2008 and 2017 (both inclusive). The query is given in Table 1
Scopus has indexed 13 documents prior to 2008 satisfying our search criterion.
Out of these, only a single document1 has received 19 citations. Likewise, no more than 3 papers/year are indexed by Scopus prior to 2008. Therefore, we chose 2008 as starting year for our data extraction. Thus, the time frame spans a decade of research in the field. Our search criteria have resulted in total of 34,655 documents. Using the graphical user interface provided by Scopus, we exclude some document types namely conference review, editorial notes, and letters. The main motivation behind the omission of these document type resides in the fact that they mostly provide information about the outlet such as scope of the conference/special issue, the number of submissions, and the acceptance rate, and normally have very low citation counts. The omission of these documents reduced the documents number to 33,623. As stated earlier that big data is a transdisciplinary field, we did not limit to literature from computer science only and allowed results fromdiverse fields such as business, medical science, and social sciences. Note that the data are downloaded on January 27, 2018, and the citation count might slightly differ at later dates. The dataset is stored in comma-separated values (CSV) format, and analysis is performed in the R statistical tool.

## Dataset

Chadegani et al. [12] compared Scopus and ISI Web of Science based on a set
of research questions. They concluded that ISI Web of Science has strong coverage dating old publications, whereas Scopus covers high-quality journals and more recent articles. Both databases provided customized search ability and are equally favored by scientists and researchers.

The timeframe for retrieving the academic publications from the Scopus database was set from the most recent six years, i.e. 2013–2018. A set of standards were created in order to obtain a suitable sample, i.e. language is English; title and keywords contain “big data”; and the document is labeled as “articles.” A total of 4,150 articles were obtained by following this process. Among these articles,
80 articles which presented incomplete information were deleted. A sample size of 4,070 was finally used for analysis. Figure 1 exhibits the procedure for data collection

The total number of articles found was XXXX
As it can be noted in Graph 1, the greatest production took place in the xxxxx

```{r tiempo, echo=FALSE, message=FALSE, warning=FALSE}

table(metadata %>% filter(tag=="year") %>% pull(value)) %>% plot()

```


# Results

## RQ1. Autores / Colaboracion

### Coautoria e Índice de Subramanyam (IS) 

```{r, echo=FALSE, message=FALSE, warning=FALSE}

# cantidad de autores
autores %>% group_by(id) %>% 
  summarize(n=n()) %>% 
  group_by(n) %>% summarise(f=n()) %>% plot()

# mas de 10 autores
autores %>% group_by(id) %>% 
  summarize(n=n()) %>% filter(n>10) %>% arrange(desc(n)) %>% pull(id)

# promedio de autores por año
autores %>% left_join(
  metadata %>% filter(tag=="year") %>%
    select(id,year=value)) %>% 
  group_by(year,id) %>% summarise(n=n()) %>%
  group_by(year) %>% summarise(avg=mean(n))

# cuantos autores por año
autores %>% left_join(
  metadata %>% 
    filter(tag=="year") %>%
    select(id,year=value)) %>% 
  group_by(year,id) %>% summarise(autores=n()) %>%
  group_by(year,autores) %>% summarise(f=n()) %>%
  ggplot(aes(y=f,x=autores)) + geom_col() + facet_wrap(~year,scales = "free_y")

```

For the complete time frame (2008 − 2017), the average number of authors per
publication is 3.45 with a standard deviation of 2.34. 13.67% of articles are
published with a single authorship, and 41% of articles have more than the
average number of authors, i.e., 41% of publications have at least 4 authors.
The surprising aspect of the findings is the share of publications with more
than 10 authors. We found that 1% of the papers have more than 10 authors.
Fig. 4 summarizes the number of authors per publication distribution.

We also analyzed the evolution of number of authors per research publications over the selected time frame. We observe that during the initial years
(2008 − 2012) 27% of publications have single authorship. During the later
years, the single authorship trend declines. In 2016 only 11.6% of papers have
single authorship, the minimum for the selected time frame. Fig. 5 depicts the
authorship trends for the time frame. It should be noted that as the number of publications are significantly lower for initial years, the data for years
2008 − 2012 is combined for reporting purposes

---> aca sube la produccion y la cantidad de autores por articulo 
(ultimos años 1 no es el mas alto )

(se puede poner la media como linea vertical en cada año?)

INDICE DE XXXX

Corresponde a la proporción de artículos con autoría múltiple (2 o más autores).

Se calcula a partir de la siguiente ecuación:

IS = Nm / Nm + Ns

donde:
Nm = Número de artículos con autoría múltiple
Ns = Número de artículos con autoría simple (1 autor)
El valor máximo que puede alcanzar este índice es 1 y corresponde a que todos
los artículos publicados por la revista tienen al menos dos autores

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# cuantos autores por año
subra <- autores %>% left_join(
  metadata %>% 
    filter(tag=="year") %>%
    select(id,year=value)) %>% 
  group_by(year,id) %>% summarise(autores=n()) %>%
  group_by(year,autores) %>% summarise(f=n()) %>%
  pivot_wider(names_from = year, values_from=f) %>% arrange(autores) 

print("Número de Artículos Distribuidos Según Número de Autores y por Período")
subra %>% janitor::adorn_totals(where = c("row","col")) 

# colSums(subra[,1:10], na.rm = TRUE) 
Ns <- colSums(subra[which(subra$autores==1),2:14], na.rm = TRUE)
Nm <- colSums(subra[which(subra$autores>1),2:14], na.rm = TRUE)
Nm / (Nm+Ns)

# estoy hay que integrarlo a la tabla anterior y agrupar los numeros de autores

```

Consistente con la idea de una tendencia hacia la colaboración, el índice de Subramanyam (IS), que calcula la proporción de artículos con dos o más autores sobre el total de documentos, muestra el progresivo incremento en la proporción de artículos en colaboración, desde un 54% en el período 1992-1996 hasta un 82% en el período 2012-2016. Por otra parte, el índice de Lawani (IL) permite complementar la noción acerca de la colaboración, calculando la media ponderada de autores por artículo en cada período. En este sentido, los resultados indican que junto con un incremento en la cantidad de artículos en coautoría, el incremento en la colaboración se ha traducido en un mayor número de autores por artículo, pasando de 1,9 autores en el período 1992-1996 a 3,4 en el período 2012-2016 (ver Tabla 3). Tomados en conjunto, ambos índices sugieren que no solo ha aumentado la proporción de artículos en los que aparecen dos o más autores firmantes, sino que también ha aumentado el número de autores firmantes por artículo.

### Colaboración entre paises

antes que nada: Which countries and institutions have contributedmost in terms ofpublications count?

**2do:esto se puede pasar a un mapa**

e.g.,
Kalantari, A., Kamsin, A., Kamaruddin, H. S., Ale Ebrahim, N., Gani, A., Ebrahimi, A., & Shamshirband, S. (2017). A bibliometric approach to tracking big data research trends. Journal of Big Data, 4(1), 1–18. https://doi.org/10.1186/s40537-017-0088-1 p9

```{r echo=FALSE, message=FALSE, warning=FALSE}

autores %>% 
  filter(!is.na(pais)) %>%
  count(pais, sort = TRUE) %>% 
  head(30) %>%
  ggplot(aes(y=n,x=reorder(pais,n))) + geom_col() +
  coord_flip() +
  labs(title="ranking +30 paises")

# autores %>% 
#   left_join(
#   metadata %>% 
#     filter(tag=="year") %>%
#     select(id,year=value)) %>%
#   filter(!is.na(pais)) %>%
#   count(pais, year, sort = TRUE) %>% 
#   pivot_wider(names_from = year, values_from=n) %>%
#   head(10)

autores %>% 
  left_join(
  metadata %>% 
    filter(tag=="year") %>%
    select(id,year=value)) %>%
  filter(!is.na(pais)) %>% 
  count(pais, year, sort = TRUE) %>% 
    filter(n>1) %>%
    ggplot(aes(x=year,y=pais,fill=n)) + geom_tile()

```


```{r colaboracion-mapa}


# library(ggmap)
# Sys.setenv(google_key = "AIzaSyAGSGP7CUWpxDJkxjVe_UKGaV0U1Ea0gn0")
# register_google(key = Sys.getenv("google_key"))
# pp <- V(paises_corr_graph) %>% as.character()
# geoloc <- ggmap::geocode(location = pp)
# geoloc$pais <- pp
# geoloc %>% write.csv("../data/geoloc.csv")

# https://datascience.blog.wzb.eu/2018/05/31/three-ways-of-visualizing-a-graph-on-a-map/
# https://rstudio-pubs-static.s3.amazonaws.com/339257_fd4db2366a1f4e44ae95a0fd6db24457.html
# http://dyerlab.github.io/popgraph/

paises <- autores %>% 
  filter(!is.na(pais)) %>%
  count(pais, sort = TRUE)

glimpse(paises)

library(rgeos)
library(rworldmap)

wmap <- getMap(resolution="high")
centroids <- gCentroid(wmap, byid=TRUE)
paises2 <- as.data.frame(centroids)
map_world <- map_data(map = "world") %>%
  filter(region != "Antarctica")

maptheme <- theme(panel.grid = element_blank()) +
  theme(axis.text = element_blank()) +
  theme(axis.ticks = element_blank()) +
  theme(axis.title = element_blank()) +
  theme(legend.position = "bottom") +
  theme(panel.grid = element_blank()) +
  theme(panel.background = element_rect(fill = "#596673")) +
  theme(plot.margin = unit(c(0, 0, 0, 0), 'cm'))

country_shapes <- geom_polygon(aes(x = long, y = lat, group = group),
                               data = map_data('world'),
                               fill = "#c9c9c9", color = "#515151",
                               size = 0.15)
mapcoords <- coord_fixed(xlim = c(-150, 180), ylim = c(-55, 80))





paises_corr <- autores %>% 
  filter(!is.na(pais)) %>%
  group_by(pais) %>% filter(n() > 50) %>% ungroup() %>%  
  widyr::pairwise_count(item = pais, feature = id, sort = TRUE) 

paises_corr_graph <- tidygraph::as_tbl_graph(
  paises_corr,
  directed = FALSE) %>%
  activate(nodes) %>% 
  inner_join( autores %>% group_by(pais) %>% summarise(f=n())
              , by=c("name"="pais") ) 

paises_corr_graph

paises_corr_graph %>% create_layout( layout = "kk") %>%
  ggraph::ggraph(layout) +
  geom_edge_link(aes(width = n), alpha = 0.2, color="gray") +
  geom_node_point(aes(size = f)) +
  geom_node_text(aes(label = name), size = 4, repel = TRUE) +
  theme_graph() +
  labs(title = "coautoria entre paises (x frecuencia)",
       subtitle = "paises con mas de 50 articulos")


# en estos dos estoy perdiendo el weight, f o lo que sea

nodes <- paises_corr_graph %>% 
  activate(nodes) %>%
  inner_join(
    rownames_to_column(paises2, "name") %>% mutate(name=tolower(name))
    ) %>% 
  mutate(id=row_number()) %>%
  select(id,name,lon=x,lat=y) %>%
  as_tibble() 

edges <- paises_corr_graph %>% 
  activate(edges) %>% 
  #rename(weights=n) %>%
  distinct() %>%
  as_tibble() %>% 
  filter(from < 30, to < 30) #hay paises sin docs?

g <- graph_from_data_frame(d = edges, 
                           directed = FALSE, 
                           vertices = nodes)

edges_for_plot <- edges %>%
  inner_join(nodes %>% select(id, lon, lat), by = c('from' = 'id')) %>%
  rename(x = lon, y = lat) %>%
  inner_join(nodes %>% select(id, lon, lat), by = c('to' = 'id')) %>%
  rename(xend = lon, yend = lat)

nodes$weight = degree(g)

node_pos <- nodes %>%
  select(lon, lat) %>%
  rename(x = lon, y = lat)   # node positions must be called x, y

ggplot(nodes) + country_shapes +
  geom_curve(aes(x = x, y = y, xend = xend, yend = yend,
                 size=n),
             data = edges_for_plot, 
             curvature = 0.33, alpha = 0.5) +
  #scale_size_continuous(guide = FALSE) + # scale for edge widths
  #scale_size_continuous(guide = FALSE, range = c(0.25, 2)) + # scale for edge widths
  geom_point(aes(x = lon, y = lat, fill=weight),           # draw nodes
             shape = 21, 
             fill = 'white',
             color = 'black', stroke = 0.5) +
  #scale_size_continuous(guide = FALSE) +    # scale for node size
  #scale_size_continuous(guide = FALSE, range = c(1, 6)) +    # scale for node size
  geom_text(aes(x = lon, y = lat, label = name, color=weight),             # draw text labels
            hjust = 0, nudge_x = 1, nudge_y = 4,
            #size = 3,
            #color = "white", 
            fontface = "bold") +
  mapcoords + maptheme

# va queriendo. tengo que poner el peso de los links, 
# y rever porque no está usa (debo estar usando correlaciones o algo asi)

```



### ranking afiliaciones

```{r echo=FALSE, message=FALSE, warning=FALSE}

academicAff <- "universi|college|school|institu|academ|politec"

cleanAff <- function(txt) {
  z <- c()
  for(i in 1:length(txt)){
    if (!is.na(txt)){
      txt2 <- str_split(string = txt[i], pattern = ",", simplify = TRUE) %>%
        as.character()
      txt3 <- grepl(
          pattern = academicAff, 
          txt2, ignore.case = TRUE)
      if(TRUE %in% txt3) {
        z <- c(z, trimws(txt2[max(which(txt3==TRUE))]))  
      } else {
        z <- c(z, trimws(txt2[1]))
      }
    } else {
      z <- c(z, NA)
    }
  } 
  return(z)  
}

autores2 <- autores %>% 
  filter(!is.na(aff)) %>%
  mutate(
    uni = grepl(
      pattern = academicAff, 
      aff, ignore.case = TRUE),
    aff2 = cleanAff(aff)
    ) 

autores2 %>% count(uni,sort=TRUE) 

autores2 %>% 
  count(uni,aff2) %>% group_by(uni) %>% 
  mutate(aff2=str_sub(aff2,1,15))%>%
  slice_max(n = 20, order_by=n) %>%
  ggplot(aes(y=n,x=reorder(aff2,n),fill=uni)) + geom_col() +
  coord_flip() +
  facet_wrap(~uni,scales = "free")+
  labs(title="ranking universidades y empresas")

autores2 %>% 
  filter(!is.na(aff)) %>%
  count(aff2, uni, sort = TRUE) %>% 
  mutate(aff2=str_sub(aff2,1,15))%>%
  ggplot(aes(y=n,x=reorder(aff2,n),fill=uni)) + geom_col() +
  facet_wrap(~uni,scales = "free")+
  labs(title="ranking +30 aff que son o no universidades")+
  coord_flip()

# en todos estos calculos hay que ver si estamos hablando de instituciones
# o de investigadores en instituciones

```

### Colaboración académica-corporativa

Co-authorship by ACC. Among the collaborative papers, 112 (2.8 percent) are
produced through the manner of ACC. Due to the small amount of publications on this topic, this finding is likely to indicate that, in the field of big data research, joint work contributed by both academia and industry is not popular. 
Table I outlines the top 10 institutions and countries/regions in the form of ACC publication. As listed in Table I, six of the institutions are affiliated with the USA, whereas the other four are relevant to China and Switzerland. In terms of countries, the USA ranks at the top with over half ACC publications (60/54 percent). China (24/21 percent), the UK (14/13 percent) and Canada (12/11 percent) have published more than ten ACC articles. The countries do not have a big representation in ACC articles.


```{r echo=FALSE, message=FALSE, warning=FALSE}

acc <- autores2 %>% count(id,uni) %>% 
  pivot_wider(names_from = uni, values_from = n) %>%
  rename(academy=2,private=3) %>%
  mutate( acc=case_when(
    !is.na(academy) & !is.na(private) ~ "acc",
    !is.na(academy) & is.na(private) ~ "pure_academy",
    is.na(academy) & !is.na(private) ~ "pure_private"
    )
  )

acc %>% count(acc)  # cuantos puros y cuantos acc

autores2 %>% inner_join(
    acc %>% select(id,acc)
  ) %>%
  filter(acc=="acc") %>%
  count(uni,aff2) %>% group_by(uni) %>% 
  slice_max(n = 20, order_by=n) %>%
  mutate(aff2=str_sub(aff2,1,15))%>%
  ggplot(aes(y=n,x=reorder(aff2,n),fill=uni)) + geom_col() +
  coord_flip() +
  facet_wrap(~uni,scales = "free_y")+
  labs(title="top instituciones que hacen ACC")

```


## RQ2. topicos y areas


### Keywords

```{r echo=FALSE, message=FALSE, warning=FALSE}


keywords <- metadata %>% filter(tag=="keyword")

keywords %>% group_by(value) %>% tally(sort = TRUE) %>% 
  #filter(value != "big data") %>%
  filter(n>100) %>% # keywords que se repitan en al menos 25 art
  # top_n(100) %>% view()
  ggplot(aes(y=n,x=reorder(value,n))) +
  geom_col() +
  coord_flip() 


library(wordcloud)
library(RColorBrewer)
library(wordcloud2)

print("wordcloud sin big data")

set.seed(1234) # for reproducibility 
# wordcloud(words = keywords %>% group_by(value) %>% tally(sort = TRUE) %>% pull(value),
#           freq = keywords %>% group_by(value) %>% tally(sort = TRUE) %>% pull(n), 
#           min.freq = 1,
#           max.words=100, random.order=FALSE, rot.per=0.35,
#           colors=brewer.pal(8, "Dark2"))

wordcloud2(data=keywords %>% count(value, sort = TRUE), size=1.6, color='random-dark')

```

Unlike other scientific fields that have clear taxonomy and classification of the sub- ject area [8], there is no classification scheme for big data. We use the frequency of keywords as metric to identify sub-areas and topics that gained the attention of researchers over the course of time. Our analysis found that the phrase “Big Data” is the most widely used keyword in our collection of records, which is unsurprising. The other keywords in order of occurrences are Data Mining (4995), Data Handling (4242) Digital Storage (3185), Cloud Computing (2921), Information Management (2795), Artificial Intelligence (2769), Distributed Computer Systems (2515), Learn- ing Systems (2261), and Algorithms (2027). In order to make the comparisons more realistic, we removed the keyword “Big Data” and designed a word cloud using the statistical software R (see Fig. 1)

In the early phase of big data research, the researcher focused mainly on uses and applications of big data research. For example, Jacob [39] discussed the challenges posed by the big data and highlighted possible solutions to overcome the challenges. Cohen et al. [16] discussed that the cost of data acquisition and storage has reduced considerably, and sophisticated data analysis has become a norm. They introduced Magnetic, Agile, Deep (MAD) data analysis practice. The proposed approach, design philosophy, and techniques were used to provide MAD analytics for Fox Audience Network. In addition, some works such as that of Brinkmann et al. [10] designed systems for large-scale data acquisition, processing, and storage. The authors claimed to collect 3 terabytes of data per day by performing continuous electrophysiological recordings of patients undergoing evaluation for epilepsy surgery. The huge amount of data generated posed storage, and processing challenges. Authors designed a platform that facilitated the acquisition, compression, and storage of large amount of data

After that, the researchers focused on application development for big data anal-
ysis as well as applications of big data in various domains. Major works in the area include Herodotou et al. [32], Chen et al. [14], Murdoch and Detsky [46], Hampton et al. [30], and Kramar et al. [1]. The diverse works focused on the developmental of new system for big data analysis [13,32], application of big data in health care [46], and ecological science [30], and studying emotional contagion in a large social networks [1]. In the later years, big data research focused on the integration of big data with
emerging technologies such as IoT [15], and social big data [7]. As the volume of the data is increasing exponentially, current research works are focusing on improving the execution times of data analysis techniques [21,45]. Similarly, the use ofGPU to solve complex big data analysis also needs further investigation [5]. Rodríguez-Mazahua et al. [51] identified data cleaning and data privacy as key issues in big data analysis.
4.4

### keywords relacionadas

```{r echo=FALSE, message=FALSE, warning=FALSE}

correlaciones <- keywords %>% 
  group_by(value) %>% filter(n() > 100) %>% ungroup() %>%  
  widyr::pairwise_cor(item = value, feature = id, sort = TRUE, method = "pearson") 

corr_graph <- tidygraph::as_tbl_graph(
  correlaciones %>% filter(correlation>=0.1), # correlaciones arriba de .1
  directed = FALSE) %>%
  activate(nodes) %>% 
  inner_join( keywords %>% group_by(value) %>% tally(), by=c("name"="value") ) 

corr_graph %>% create_layout( layout = "dh") %>%
  ggraph::ggraph(layout) + 
  geom_edge_link(aes(width = correlation), alpha = 0.2) + 
  geom_node_point(aes(size = n)) +
  geom_node_text(aes(label = name), size = 4, repel = TRUE) +
  theme_graph() +
  labs(title = "Keyword correlation network") 

```

### mapa semantico de "big data"

esto del mapa semantico es un invento mio. ja.

```{r echo=FALSE, message=FALSE, warning=FALSE}

campo1 <- correlaciones %>% filter( item1 == "big data" ) %>% 
  top_n( n=25 , correlation ) %>% select( "item1", "item2" , "correlation" ) 
campo2 <- correlaciones %>% filter( item2 %in% campo1$item2 , item1 != "big data" ) %>% 
  top_n( n=100 , correlation ) %>% select( "item1", "item2" , "correlation" ) 
nodos1 <- campo1 %>% rename( item=item2 ) %>% distinct( item ) 
nodos2 <- campo2 %>% rename( item=item1 ) %>% distinct( item )
nodos2b <- dplyr::filter(nodos2, !item %in% intersect(nodos1$item, nodos2$item))      
if (nrow(nodos1) > 0){ nodos1$nivel=1 }
if (nrow(nodos2b) > 0){ nodos2b$nivel=2 } 
nodos<-rbind(nodos1,nodos2b)       
nodos<-rbind(nodos,c("big data" ,3))
semnet <- rbind(campo1, campo2) 
rm(nodos1,nodos2,nodos2b,campo1,campo2,nodos)

semgraph <- tidygraph::as_tbl_graph(semnet, directed = FALSE) %>%
  activate(nodes) %>% 
  left_join( keywords %>% group_by(value) %>% tally(), by=c("name"="value") ) 

semgraph %>% create_layout( layout = "gem") %>%
  ggraph::ggraph(layout) + 
  geom_edge_link(aes(width = correlation), alpha = 0.2) + 
  geom_node_point(aes(size = n)) +
  geom_node_text(aes(label = name), size = 4, repel = TRUE) +
  theme_graph() +
  labs(title = "Keyword correlation to 'big data'",
    subtitle = "1 and 2 degree") 

semgraph %>% 
  activate(nodes) %>% 
  mutate(
    neighbors = centrality_degree(), # cantidad de vecinos
    centrality = centrality_authority() # centralidad entre vecinos
  ) %>%
  # filter(!node_is_isolated()) %>%
  mutate(
    # group = group_infomap(trials = 500),
    group = group_leading_eigen(steps = 100),
    # group = group_louvain() # ok
    # group = group_optimal() # ok
    # group = group_walktrap(steps = 10) 
  ) %>%
  create_layout( layout = "gem") %>%
  ggraph::ggraph(layout) + 
    geom_edge_link(aes(width = correlation), alpha = 0.1) + 
    geom_node_point(aes(size = n, color = factor(group))) +
    geom_node_text(aes(label = name), size = 4, repel = TRUE) +
    theme_graph() +
    labs(title = "Keyword correlation to 'big data'",
         subtitle = "1 and 2 degree") 

rm(semnet,semgraph)
rm(corr_graph, correlaciones, keywords)

```

### Topic modelling sobre abstracts

```{r echo=FALSE, message=FALSE, warning=FALSE}

library(quanteda)
library(stm)
library(tidytext)
library(textstem)

limpiar <- function(txt) {
  txt <- tolower(txt)
  txt <- gsub("[^a-z ]","",txt)
  txt <- gsub("big data","big_data",txt, fixed = TRUE)
  txt <- gsub("â"," ",txt, fixed = TRUE)
  txt <- trimws(txt)
  return(txt)
}


abstracts <- metadata %>% filter(tag=="abstract") %>%
  mutate(value=limpiar(value))

tidy_abs <- abstracts %>%
  select(-tag,-source) %>%
  unnest_tokens(output = word, input = value) %>%
  anti_join(stop_words) %>% # remove stopwords
  mutate(len = str_length(word)) %>% filter(len>2) %>% select(-len) %>% # remove 1-2 char words
  mutate(word=textstem::lemmatize_words(x = word %>% unlist()))  # lemmatize


dfm_abs <- tidy_abs %>%
  count(id, word, sort = TRUE) %>%
  tidytext::cast_dfm(id, word, n)

dfm_abs_idf <- tidy_abs %>%
  count(id, word, sort = TRUE) %>%
  tidytext::bind_tf_idf(tbl = ., document = id, term = word, n = n)

# 2do: tengo que bajar tf_idf a tm
# https://www.tidytextmining.com/dtm.html

# tm basico con stm + tidy -----------------
# https://juliasilge.com/blog/sherlock-holmes-stm/

topic_model <- stm(dfm_abs, K = 20, verbose = FALSE, 
                   init.type = "Spectral", max.em.its = 2)

td_beta <- tidy(topic_model)

td_beta %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  ungroup() %>%
  mutate(topic = paste0("Topic ", topic),
    term = reorder_within(term, beta, topic)) 

td_gamma <- tidy(topic_model, matrix = "gamma", 
  document_names = rownames(dfm_abs))

library(ggthemes)

top_terms <- td_beta %>%
  arrange(beta) %>%
  group_by(topic) %>%
  top_n(100, beta) %>%
  arrange(-beta) %>%
  select(topic, term) %>%
  summarise(terms = list(term)) %>%
  mutate(terms = map(terms, paste, collapse = ", ")) %>% 
  unnest(cols=c(terms))

gamma_terms <- td_gamma %>%
  group_by(topic) %>%
  summarise(gamma = mean(gamma)) %>%
  arrange(desc(gamma)) %>%
  left_join(top_terms, by = "topic") %>%
    mutate(topic = paste0("Topic ", topic),
      topic = reorder(topic, gamma))

gamma_terms %>%
  #top_n(50, gamma) %>%
  ggplot(aes(topic, gamma, label = terms, fill = topic)) +
  geom_col(show.legend = FALSE) +
  geom_text(hjust = 0, nudge_y = 0.0005 ) +
  coord_flip() +
  #scale_y_continuous(expand = c(0,0),
  #  limits = c(0, 0.09)) +
  theme_tufte(ticks = FALSE) +
  theme(plot.title = element_text(size = 16 ),
    plot.subtitle = element_text(size = 13)) +
  labs(x = NULL, y = expression(gamma),
    title = "Top topics by prevalence")

gamma_terms %>%
  select(topic, gamma, terms) %>%
  knitr::kable(digits = 3, 
    col.names = c("Topic", "Expected topic proportion", "Top 7 terms"))

# # cuales son los +terminos de cada topico?
# gamma_terms %>%
#   select(topic, gamma, terms)
# 
# # cuales son los +docs de cada topico?
# docs_topico <- td_gamma %>%
#   group_by(topic) %>%
#   arrange(desc(gamma)) %>% 
#   top_n(100)
# docs_topico

# 2do: falta mismo preprocesamiento a ambas tablas
# cuales / cuantas palabras del tm estan en los keywords
# cuantos keywords aparecen sobre el total de palabras x topic?
# y cuan exclusivos son? ----> esta puede ser la nocion conceptual a explorar?

rm(x)

```

presentar como tabla de temas con topkeywords

## RQ3. Citation

### top venues

We identify the top 10 venues for publications in terms of number of citations. In addition, we also record the number of publication made in each venue. Lecture Notes in Computer Science (LNCS)2 received the most number of citations (3064), which published the most number of articles as well (2538). This resulted in 1.20 citations per publication. LNCS is followed by Proceedings of the VLDB Endowment which received 2369 citations for 99 publications. The top 15 venues based on absolute cita- tion counts are given in Table 5. The table also lists the number of publications and citations/publication for each venue. In terms of citations per publication, MIS Quar- terly: Management Information Systems ranks at the top. However, a close inspection of the data reveals that the MIS Quarterly: Management Information Systems has received 1111 citations for 5 publications. Out of 1111 citations, 1098 citations are for [13], whichmeans that the rest of4 publications received only 13 citations. Informa- tion Communication and Society ranks 2 based on citations/publication; however, one publication [9] accrued 999 citations, whereas the remaining 13 publications acquired 86 citations. Other top venues based on the citation/publication include Proceedings of the National Academy of Sciences of the United States ofAmerica (66.9), Nature (43.3), and IEEE Transactions on Knowledge and Data Engineering (31.78)

Table 5 Top venues by most number of citations Venue
x Citation count 
x Publication count 
x Citations/publication


lo que trajimos de anystyle

```{r message=FALSE, warning=FALSE}

table(references$CATEGORY)

```

armamos nuestra propia tabla

```{r}

ref <- references %>% 
  filter(CATEGORY %in% c("ARTICLE","BOOK","INPROCEEDINGS")) %>% 
  select(AUTHOR, JOURNAL, TITLE, DATE, DOI, BOOKTITLE,id) %>%
  rowwise() %>% # bajar autores a string
      mutate(authors = paste(AUTHOR, collapse=', ')) %>%
      ungroup() %>%
  mutate(
    date_anystyle = as.integer(DATE), # fecha parseada por anystyle
    date_titulo = as.integer(sub("\\D*(\\d{4}).*", "\\1", TITLE)), # fecha del titulo
  ) %>%
  mutate(date = case_when(
    is.na(date_anystyle) & !is.na(date_titulo) ~ date_titulo,
    is.na(date_titulo) & !is.na(date_anystyle) ~ date_anystyle,
    !is.na(date_anystyle) & !is.na(date_titulo) ~ date_anystyle,
    is.na(date_anystyle) & is.na(date_titulo) ~ NA_integer_
  )) %>% 
  mutate( ref = paste(
      str_replace_all(string = authors, pattern = "[^[A-Za-z ,]]", replacement = ""),
      date,
      str_replace_all(string = TITLE, pattern = "[^[A-Za-z ]]", replacement = "") %>%
        str_sub(string = ., 1, 20)
      )
  ) %>%
  mutate( ref = trimws(tolower(ref)))

glimpse(ref)

# 2do: falta limpiar y borrar los na obvios

```
cantidad de referencias??? 

```{r}
ref %>% count(ref) %>% count(n, sort = TRUE) %>% plot()
```

### citas x año x articulos

What is the average number of citations/publications?

```{r echo=FALSE, message=FALSE, warning=FALSE}

ref %>% 
  left_join(
    metadata %>% # citas por año
    filter(tag=="year") %>%
    select(id,year=value)) %>% 
    mutate(year=as.integer(year)
  ) %>%
  count(year, name = 'references') %>%
  ungroup() %>%
  left_join(
    metadata %>% # articulos por año
    filter(tag=="year") %>%
    select(id,year=value) %>% 
    mutate(year=as.integer(year)) %>%
             count(year, name = 'articulos')
  ) %>%
  mutate(
    ref_art = references / articulos
  )

```


### Articulos más influyentes (+citas)


```{r echo=FALSE, message=FALSE, warning=FALSE}

ref %>% 
  count(ref,sort = TRUE) %>% head()

```

#### publications in the selected time frame

**2do: calcular**

```{r echo=FALSE, message=FALSE, warning=FALSE}


```


#### Top cited publications for each year

```{r echo=FALSE, message=FALSE, warning=FALSE}

ref %>% 
    left_join(
      metadata %>% 
      filter(tag=="year") %>%
      select(id,year=value)) %>% 
      mutate(year=as.integer(year)
    ) %>%
    group_by(year,ref) %>%
    summarise(n=n()) %>%
    filter(n>1) %>%
    slice_max(order_by = n, n = 5, with_ties = FALSE) %>%
  ggplot(aes(y=n,x=ref)) + geom_col() + facet_wrap(~year) + coord_flip()

```

#### Top 10 publications by normalized score

**2do: calcular**


```{r echo=FALSE, message=FALSE, warning=FALSE}

```


#### referencias por topicos (ya sea x tm o keywords)

**2do: calcular**


```{r echo=FALSE, message=FALSE, warning=FALSE}

```

# Discussion

**meter comparacion con el general**

Discussions and suggestions for future research This study presented a comprehensive review of the current studies related to big data. Based on a sample size of 4,070 articles obtained from the Scopus database published between 2013 and 2018, this study revealed an array of interesting findings by utilizing the bibliometric approach and SciVal metrics. The results have provided a comprehensive understanding of big data research, in particular, in view of the scope, co-production and performance of this research stream.

This paper delivers a comprehensive review of research in BDA to foster a better understanding of a pervasive and new area. Several fundamental research questions that are relevant to current research efforts are focusing on the BDAA have been answered while providing a better platform for further evaluation and research in this area. A robust methodology called “Systematic Network Analysis of Literature” has been adopted for this purpose. This study conducted an SLR of 79 published papers and bibliometric analysis of 516 published papers from various journals, from 2014 to 2018. The research papers included in the review were selected based on the title, introduction, abstract, conclusion and research methods. A bibliometric analysis includes an integrated and systematic review of the literature to explore key themes and the theoretical framework underpinning journals, the field of inquiry or papers (Garc?ıa-Lillo et al., 2018). Due to their benefits over other approaches

## Limitations and future scope 

While this review paper has been completed rigorously, some limitations may present suggestions for future review papers. The data were collected from different journals, whereas the document examined did not include unpublished papers, master or doctoral theses and textbooks regarding BDAA. While this study has attempted to provide a comprehensive review based on the current literature, the data can be collected from the resources mentioned above as a recommendation for future studies, and the data reported and obtained in this study can be compared with the results obtained from those resources. This paper reviewed classified papers in the seven categories; it is suggested that future papers can classify and review papers in different areas and subcategories. Another limitation of this review was the extraction of all papers from English-language journals only. Consequently, the review did not include scientific journals in other languages. This study,
however, believes that most of the reviewed papers were from international journals. This study carefully selected and summarized the papers available in the Web of Science databases from several publishers. However, certain relevant outlets remained outside the scope of the current study. Therefore, future researchers may try to review papers not considered in the current review article. Another limitation is that in order to address the second research question, BDAA in different countries, the bibliometric analysis was carried out with only specific keywords to select Webof Science database papers; future researchmay aim at using different keywords and objectives to obtain different results. In the future effect of BDA on supply chain risk and flexibility can be studied. Role of artificial intelligence (AI) on BDA can be further analyze
It is important to present the limitation of the study, as it might be possible that the results are not obtained if the same set of experiments is repeated again. We downloaded the data from Scopus on January 27, 2018. As Scopus has data download limits, the data were downloaded in an incremental manner and later combined. It is possible that the reader may find the number of citations for various articles different than the ones reported here. There can be several reasons for this. For example, the article might have accumulated more citations over time. It is also possible that various sources might report different statistics for the same article. A noticeable example is the case of publication“Data mining with big data.” The paper according to Scopus has received 681 citations, whereas Google Scholar has recorded 1320 citations for the publication till 2017. The publisher IEEE Transactions on Knowledge and Data Engineering recorded 524 citations for the same publication. The difference between the citation count of Scopus and other sources can be attributed to the fact that Scopus citations are based on Scopus-indexed publications only. It is also important to mention that Google Scholar citations also include non-academic citations. As stated earlier that a variety of past studies has validated the authenticity of Scopus, therefore, our results are also based on the statistics of Scopus only

# Referencias

